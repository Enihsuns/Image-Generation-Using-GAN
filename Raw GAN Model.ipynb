{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw GAN Model\n",
    "Reference: https://blog.csdn.net/sunqiande88/article/details/80219842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# 定义生成器网络G\n",
    "class NetG(nn.Module):\n",
    "    def __init__(self, ngf, nz):\n",
    "        super(NetG, self).__init__()\n",
    "        # layer1输入的是一个100x1x1的随机噪声, 输出尺寸(ngf*8)x4x4\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # layer2输出尺寸(ngf*4)x8x8\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # layer3输出尺寸(ngf*2)x16x16\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # layer4输出尺寸(ngf)x32x32\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # layer5输出尺寸 3x96x96\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf, 3, 5, 3, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    # 定义NetG的前向传播\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# 定义鉴别器网络D\n",
    "class NetD(nn.Module):\n",
    "    def __init__(self, ndf):\n",
    "        super(NetD, self).__init__()\n",
    "        # layer1 输入 3 x 96 x 96, 输出 (ndf) x 32 x 32\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, ndf, kernel_size=5, stride=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        # layer2 输出 (ndf*2) x 16 x 16\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        # layer3 输出 (ndf*4) x 8 x 8\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        # layer4 输出 (ndf*8) x 4 x 4\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        # layer5 输出一个数(概率)\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    # 定义NetD的前向传播\n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found 0 files in subfolders of: E:\\Work\\Image-Generation-Using-GAN\\data\nSupported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-cd1206be55b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ])\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m dataloader = torch.utils.data.DataLoader(\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, target_transform, loader)\u001b[0m\n\u001b[0;32m    176\u001b[0m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS,\n\u001b[0;32m    177\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                                           target_transform=target_transform)\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             raise(RuntimeError(\"Found 0 files in subfolders of: \" + root + \"\\n\"\n\u001b[1;32m---> 79\u001b[1;33m                                \"Supported extensions are: \" + \",\".join(extensions)))\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found 0 files in subfolders of: E:\\Work\\Image-Generation-Using-GAN\\data\nSupported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn as nn\n",
    "from random import randint\n",
    "\n",
    "batchSize = 64\n",
    "imageSize = 96\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "epoch = 25\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "data_path = './data'\n",
    "outf = './imgs'\n",
    "\n",
    "# 定义是否使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#图像读入与预处理\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Scale(imageSize),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(data_path, transform=transforms)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=batchSize,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "netG = NetG(ngf, nz).to(device)\n",
    "netD = NetD(ndf).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "label = torch.FloatTensor(batchSize)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "for epoch_idx in range(1, epoch + 1):\n",
    "    for i, (imgs,_) in enumerate(dataloader):\n",
    "        # 固定生成器G，训练鉴别器D\n",
    "        optimizerD.zero_grad()\n",
    "        ## 让D尽可能的把真图片判别为1\n",
    "        imgs=imgs.to(device)\n",
    "        output = netD(imgs)\n",
    "        label.data.fill_(real_label)\n",
    "        label=label.to(device)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        ## 让D尽可能把假图片判别为0\n",
    "        label.data.fill_(fake_label)\n",
    "        noise = torch.randn(batchSize, nz, 1, 1)\n",
    "        noise=noise.to(device)\n",
    "        fake = netG(noise)  # 生成假图\n",
    "        output = netD(fake.detach()) #避免梯度传到G，因为G不用更新\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        errD = errD_fake + errD_real\n",
    "        optimizerD.step()\n",
    "\n",
    "        # 固定鉴别器D，训练生成器G\n",
    "        optimizerG.zero_grad()\n",
    "        # 让D尽可能把G生成的假图判别为1\n",
    "        label.data.fill_(real_label)\n",
    "        label = label.to(device)\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.3f Loss_G %.3f'\n",
    "              % (epoch_idx, epoch, i, len(dataloader), errD.item(), errG.item()))\n",
    "\n",
    "    vutils.save_image(fake.data,\n",
    "                      '%s/fake_samples_epoch_%03d.png' % (outf, epoch_idx),\n",
    "                      normalize=True)\n",
    "    torch.save(netG.state_dict(), '%s/netG_%03d.pth' % (outf, epoch_idx))\n",
    "    torch.save(netD.state_dict(), '%s/netD_%03d.pth' % (outf, epoch_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
